>>>> Flash Attention installed
>>>> Flash RoPE installed
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.57s/it]
Resolving data files:   0%|          | 0/23 [00:00<?, ?it/s]Resolving data files:   4%|▍         | 1/23 [00:00<00:13,  1.68it/s]Resolving data files:  30%|███       | 7/23 [00:00<00:01, 11.68it/s]Resolving data files: 100%|██████████| 23/23 [00:00<00:00, 29.88it/s]
/home/hanshis/anaconda3/envs/torch/lib/python3.9/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.
  table = cls._concat_blocks(blocks, axis=0)
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:09<00:00,  9.70s/it]100%|██████████| 1/1 [00:09<00:00,  9.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:12<00:00, 12.09s/it]100%|██████████| 1/1 [00:12<00:00, 12.09s/it]
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:00<00:07,  2.53it/s] 25%|██▌       | 5/20 [00:00<00:01, 11.70it/s] 45%|████▌     | 9/20 [00:00<00:00, 18.02it/s] 65%|██████▌   | 13/20 [00:00<00:00, 22.44it/s] 85%|████████▌ | 17/20 [00:00<00:00, 25.50it/s]100%|██████████| 20/20 [00:00<00:00, 20.39it/s]
Cached Size: 2000 | Max Budget: 2200 | Start Size: 64 | Recent Size: 156 | Gamma: 130 | Skip Start Layers: 1
0.00015742826461791993 128 2000 2000 warm up done
  0%|          | 0/20 [00:00<?, ?it/s] 20%|██        | 4/20 [00:00<00:00, 32.29it/s] 40%|████      | 8/20 [00:00<00:00, 32.90it/s] 60%|██████    | 12/20 [00:00<00:00, 33.09it/s] 80%|████████  | 16/20 [00:00<00:00, 33.19it/s]100%|██████████| 20/20 [00:00<00:00, 33.23it/s]100%|██████████| 20/20 [00:00<00:00, 33.11it/s]
Cached Size: 2000 | Max Budget: 2200 | Start Size: 64 | Recent Size: 156 | Gamma: 130 | Skip Start Layers: 1
Cached Size: 2000 | Max Budget: 2200 | Start Size: 64 | Recent Size: 156 | Gamma: 130 | Skip Start Layers: 1
0.025525908708572388 0.001228316307067871 1 2000 2000
0.0258585364818573 0.001228316307067871 2 2000 2000
0.02538873016834259 0.001228316307067871 4 2000 2000
0.025597360610961913 0.001228316307067871 8 2000 2000
0.025711258053779603 0.001228316307067871 12 2000 2000
0.02591567587852478 0.001228316307067871 16 2000 2000
0.027131852030754088 0.001228316307067871 20 2000 2000
0.027190835118293764 0.001228316307067871 24 2000 2000
0.027267046570777893 0.001228316307067871 28 2000 2000
0.026407882928848266 0.001228316307067871 32 2000 2000
0.027764573097229003 0.001228316307067871 36 2000 2000
0.02780312466621399 0.001228316307067871 40 2000 2000
0.027891060709953307 0.001228316307067871 44 2000 2000
0.028016881704330445 0.001228316307067871 48 2000 2000
0.028112884759902954 0.001228316307067871 52 2000 2000
0.028267673015594484 0.001228316307067871 56 2000 2000
0.02834443116188049 0.001228316307067871 60 2000 2000
0.028332817673683168 0.001228316307067871 64 2000 2000
0.03000024700164795 0.001228316307067871 68 2000 2000
0.03020924425125122 0.001228316307067871 72 2000 2000
0.03031382882595062 0.001228316307067871 76 2000 2000
0.03036292278766632 0.001228316307067871 80 2000 2000
0.03038701832294464 0.001228316307067871 84 2000 2000
0.030486654758453368 0.001228316307067871 88 2000 2000
0.030568586587905885 0.001228316307067871 92 2000 2000
0.03057220470905304 0.001228316307067871 96 2000 2000
0.02974263119697571 0.001228316307067871 100 2000 2000
0.029706610083580016 0.001228316307067871 104 2000 2000
0.02984033405780792 0.001228316307067871 108 2000 2000
0.029907102942466735 0.001228316307067871 112 2000 2000
0.030532872676849364 0.001228316307067871 116 2000 2000
0.0304624559879303 0.001228316307067871 120 2000 2000
0.030538805961608885 0.001228316307067871 124 2000 2000
0.030611884951591492 0.001228316307067871 128 2000 2000
