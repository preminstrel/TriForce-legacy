{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: torch.Size([4, 5, 32, 128]), k: torch.Size([4, 100, 32, 128]), v: torch.Size([4, 100, 32, 128])\n"
     ]
    }
   ],
   "source": [
    "from flash_attn import flash_attn_with_kvcache\n",
    "import torch\n",
    "\n",
    "bsz = 4\n",
    "n_heads = 32\n",
    "q_len = 5\n",
    "kv_len = 100\n",
    "d_model = 128\n",
    "\n",
    "q = torch.randn(bsz, q_len, n_heads, d_model).half().cuda()\n",
    "k = torch.randn(bsz, kv_len, n_heads, d_model).half().cuda()\n",
    "v = torch.randn(bsz, kv_len, n_heads, d_model).half().cuda()\n",
    "\n",
    "print(f\"q: {q.shape}, k: {k.shape}, v: {v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([100, 100, 100, 100], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_len = 100\n",
    "seq_len = torch.full((bsz,), data_len, dtype=torch.int32).cuda()\n",
    "\n",
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10070, 10068, 10140, 10007], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = torch.randint(low=10000, high=10240, size=(bsz,), dtype=torch.int32).cuda()\n",
    "\n",
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache_seqlens: tensor([ 30,  20,  10, 100], device='cuda:0', dtype=torch.int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 30],\n",
       "        [ 20],\n",
       "        [ 10],\n",
       "        [100]], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache_seqlens = torch.tensor([30, 20, 10, 100], dtype=torch.int32).cuda()\n",
    "print(f\"cache_seqlens: {cache_seqlens}\")\n",
    "\n",
    "import torch\n",
    "\n",
    "range_tensor = torch.arange(1).cuda()\n",
    "\n",
    "# Use broadcasting to add the starting index (cache_seqlens) to the range_tensor\n",
    "# cache_seqlens[:, None] changes the shape to make it compatible for broadcasting\n",
    "storage_ids_no_loop = cache_seqlens[:, None] + range_tensor\n",
    "\n",
    "storage_ids_no_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 31,  21,  11, 101], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache_seqlens +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5, 32, 128])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute each sequence's attn_output based on the cache_seqlens\n",
    "\n",
    "attn_output_test = flash_attn_with_kvcache(q, k_cache=k, v_cache=v, cache_seqlens=cache_seqlens, softmax_scale=1/torch.sqrt(torch.tensor(128, dtype=torch.float16)), causal=True)\n",
    "attn_output_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_seqlens = torch.full((bsz,), kv_len, dtype=torch.int32).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([100, 100, 100, 100], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache_seqlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_truct: torch.Size([1, 30, 32, 128]), v_truct: torch.Size([1, 30, 32, 128])\n",
      "k_truct: torch.Size([1, 20, 32, 128]), v_truct: torch.Size([1, 20, 32, 128])\n",
      "k_truct: torch.Size([1, 10, 32, 128]), v_truct: torch.Size([1, 10, 32, 128])\n",
      "k_truct: torch.Size([1, 100, 32, 128]), v_truct: torch.Size([1, 100, 32, 128])\n"
     ]
    }
   ],
   "source": [
    "attn_output_refs = []\n",
    "bsz_idx = 0\n",
    "for i in cache_seqlens:\n",
    "    k_truct = k[bsz_idx:bsz_idx +1, :i, :, :]\n",
    "    v_truct = v[bsz_idx:bsz_idx+1, :i, :, :]\n",
    "    print(f\"k_truct: {k_truct.shape}, v_truct: {v_truct.shape}\")\n",
    "    attn_output_ref = flash_attn_with_kvcache(q[bsz_idx:bsz_idx+1], k_cache=k_truct, v_cache=v_truct, softmax_scale=1/torch.sqrt(torch.tensor(128, dtype=torch.float16)), causal=True)\n",
    "    attn_output_refs.append(attn_output_ref)\n",
    "    bsz_idx += 1\n",
    "    assert torch.allclose(attn_output_test[bsz_idx-1:bsz_idx], attn_output_ref, atol=1e-3), f\"bsz_idx: {bsz_idx-1}, attn_output_test: {attn_output_test[bsz_idx-1:bsz_idx]}, attn_output_ref: {attn_output_ref}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.2140, -0.6909,  0.8154,  ...,  0.1670,  0.1050,  0.2377],\n",
       "          [-0.2330, -0.0182, -0.0674,  ...,  0.4292, -0.3501, -0.2179],\n",
       "          [-0.1499, -0.4426,  0.2878,  ...,  0.6382,  0.6982,  0.1709],\n",
       "          ...,\n",
       "          [ 0.4016,  0.0766,  0.1216,  ...,  0.1700, -0.5640, -0.2235],\n",
       "          [ 0.0381, -0.0160,  0.5967,  ..., -0.0669,  0.2133,  0.0343],\n",
       "          [-0.2751,  0.0526, -0.2031,  ..., -0.0446,  0.0818,  0.4768]],\n",
       "\n",
       "         [[ 0.2859, -0.4028, -0.5942,  ...,  0.5195, -1.3359, -0.7524],\n",
       "          [-0.1333, -0.0883, -0.0278,  ...,  0.0974, -0.2502, -0.1698],\n",
       "          [-0.1354, -0.2040, -0.0078,  ..., -0.1407,  0.0199,  0.0045],\n",
       "          ...,\n",
       "          [ 0.7915,  0.1787, -0.0656,  ...,  0.3474, -0.4114,  0.0555],\n",
       "          [-0.4763, -0.0390, -0.0581,  ..., -0.2144,  0.3833,  0.0718],\n",
       "          [-0.0518,  0.3843, -0.5093,  ..., -0.0288, -0.3535,  0.6528]],\n",
       "\n",
       "         [[ 0.1794, -0.5269,  0.6548,  ...,  0.3735, -0.1522,  0.2505],\n",
       "          [-0.0624, -0.4580,  0.0086,  ..., -0.0738,  0.1107,  0.0717],\n",
       "          [-0.2291, -0.3105, -0.0728,  ...,  0.5562,  0.2737, -0.2228],\n",
       "          ...,\n",
       "          [ 0.3701, -0.4207, -0.1301,  ..., -0.2004, -0.8394, -0.3789],\n",
       "          [-0.3008,  0.4302, -0.0850,  ..., -0.1290,  0.4241, -0.4785],\n",
       "          [-0.3496, -0.3115, -0.3560,  ..., -0.3535,  0.6021,  0.1203]],\n",
       "\n",
       "         [[ 0.1892, -0.5381,  0.4734,  ...,  0.6143, -0.3503,  0.3196],\n",
       "          [-0.2085, -0.0643, -0.4065,  ...,  0.2214, -0.3579, -0.4009],\n",
       "          [-0.0140, -0.4778,  0.4187,  ...,  0.5449,  0.1036, -0.2393],\n",
       "          ...,\n",
       "          [ 0.6768,  0.0267, -0.4429,  ...,  0.0676, -0.6655, -0.0437],\n",
       "          [-0.1798,  0.2537, -0.0750,  ..., -0.2072,  0.2517, -0.3064],\n",
       "          [-0.4929, -0.3716, -0.1866,  ..., -0.4080, -0.0454,  0.8208]],\n",
       "\n",
       "         [[ 0.9038, -0.2864,  0.2732,  ...,  0.9302, -0.2111,  0.0185],\n",
       "          [-0.0106,  0.0586,  0.0931,  ..., -0.0264, -0.1143, -0.1656],\n",
       "          [-0.2012, -0.1141, -0.1742,  ...,  0.0596,  0.1791, -0.0415],\n",
       "          ...,\n",
       "          [ 0.5073, -0.1493, -0.0503,  ..., -0.4673, -0.9492, -0.0894],\n",
       "          [-0.4695,  0.2418, -0.2935,  ..., -0.1576,  0.4773, -0.0136],\n",
       "          [-0.3303, -0.0729, -0.4058,  ..., -0.4080,  0.2216,  0.4111]]]],\n",
       "       device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output_refs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2140, -0.6909,  0.8154,  ...,  0.1670,  0.1050,  0.2377],\n",
       "         [-0.2330, -0.0182, -0.0674,  ...,  0.4292, -0.3501, -0.2179],\n",
       "         [-0.1499, -0.4426,  0.2878,  ...,  0.6382,  0.6982,  0.1709],\n",
       "         ...,\n",
       "         [ 0.4016,  0.0766,  0.1216,  ...,  0.1700, -0.5640, -0.2235],\n",
       "         [ 0.0381, -0.0160,  0.5967,  ..., -0.0669,  0.2133,  0.0343],\n",
       "         [-0.2751,  0.0526, -0.2031,  ..., -0.0446,  0.0818,  0.4768]],\n",
       "\n",
       "        [[ 0.2859, -0.4028, -0.5942,  ...,  0.5195, -1.3359, -0.7524],\n",
       "         [-0.1333, -0.0883, -0.0278,  ...,  0.0974, -0.2502, -0.1698],\n",
       "         [-0.1354, -0.2040, -0.0078,  ..., -0.1407,  0.0199,  0.0045],\n",
       "         ...,\n",
       "         [ 0.7915,  0.1787, -0.0656,  ...,  0.3474, -0.4114,  0.0555],\n",
       "         [-0.4763, -0.0390, -0.0581,  ..., -0.2144,  0.3833,  0.0718],\n",
       "         [-0.0518,  0.3843, -0.5093,  ..., -0.0288, -0.3535,  0.6528]],\n",
       "\n",
       "        [[ 0.1794, -0.5269,  0.6548,  ...,  0.3735, -0.1522,  0.2505],\n",
       "         [-0.0624, -0.4580,  0.0086,  ..., -0.0738,  0.1107,  0.0717],\n",
       "         [-0.2291, -0.3105, -0.0728,  ...,  0.5562,  0.2737, -0.2228],\n",
       "         ...,\n",
       "         [ 0.3701, -0.4207, -0.1301,  ..., -0.2004, -0.8394, -0.3789],\n",
       "         [-0.3008,  0.4302, -0.0850,  ..., -0.1290,  0.4241, -0.4785],\n",
       "         [-0.3496, -0.3115, -0.3560,  ..., -0.3535,  0.6021,  0.1203]],\n",
       "\n",
       "        [[ 0.1892, -0.5381,  0.4734,  ...,  0.6143, -0.3503,  0.3196],\n",
       "         [-0.2085, -0.0643, -0.4065,  ...,  0.2214, -0.3579, -0.4009],\n",
       "         [-0.0140, -0.4778,  0.4187,  ...,  0.5449,  0.1036, -0.2393],\n",
       "         ...,\n",
       "         [ 0.6768,  0.0267, -0.4429,  ...,  0.0676, -0.6655, -0.0437],\n",
       "         [-0.1798,  0.2537, -0.0750,  ..., -0.2072,  0.2517, -0.3064],\n",
       "         [-0.4929, -0.3716, -0.1866,  ..., -0.4080, -0.0454,  0.8208]],\n",
       "\n",
       "        [[ 0.9038, -0.2864,  0.2732,  ...,  0.9302, -0.2111,  0.0185],\n",
       "         [-0.0106,  0.0586,  0.0931,  ..., -0.0264, -0.1143, -0.1656],\n",
       "         [-0.2012, -0.1141, -0.1742,  ...,  0.0596,  0.1791, -0.0415],\n",
       "         ...,\n",
       "         [ 0.5073, -0.1493, -0.0503,  ..., -0.4673, -0.9492, -0.0894],\n",
       "         [-0.4695,  0.2418, -0.2935,  ..., -0.1576,  0.4773, -0.0136],\n",
       "         [-0.3303, -0.0729, -0.4058,  ..., -0.4080,  0.2216,  0.4111]]],\n",
       "       device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 100, 32, 128])\n",
      "torch.Size([2, 32, 128])\n",
      "torch.Size([2, 32, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 定义两个tensor和index\n",
    "tensor1 = torch.zeros(2, 100, 32, 128).cuda()  # 目标tensor\n",
    "tensor2 = torch.randn(2, 5, 32, 128).cuda()    # 源tensor\n",
    "indices = torch.tensor([[9, 10, 11, 12, 13], [29, 30, 31, 32, 33]]).cuda()\n",
    "\n",
    "# 将indices调整形状以适配scatter的输入要求\n",
    "# 我们需要一个与tensor1在除了第二维之外的其他维度匹配的indices形状\n",
    "indices_expanded = indices.unsqueeze(-1).unsqueeze(-1).expand(-1, -1, 32, 128)\n",
    "\n",
    "# 使用scatter_并行复制tensor2到tensor1的指定位置\n",
    "# 这将直接修改tensor1的内容\n",
    "tensor1.scatter_(1, indices_expanded, tensor2)\n",
    "\n",
    "# 验证操作，例如检查tensor1的某些索引位置是否已更新\n",
    "# 注意：实际运行中可能不需要这些验证步骤，它们只是为了演示操作成功\n",
    "print(tensor1.shape)  # 应为 torch.Size([2, 100, 32, 128])\n",
    "print(tensor1[:, 9, :, :].shape)  # 检查一个被更新的索引位置，应为 torch.Size([2, 32, 128])\n",
    "print(tensor1[:, 29, :, :].shape)  # 检查另一个被更新的索引位置，同样应为 torch.Size([2, 32, 128])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32, 128])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1[0, 9:13].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3,4])\n",
    "a[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 32, 128])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(tensor1[0, 9:14], tensor2[0], atol=1e-3)\n",
    "torch.allclose(tensor1[1, 29:34], tensor2[1], atol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-8.5044e-01, -1.0663e+00, -1.7845e-01,  ..., -7.5510e-01,\n",
       "            1.0224e+00, -1.2777e+00],\n",
       "          [ 7.5481e-01,  6.4249e-02, -3.8490e-01,  ..., -6.6143e-01,\n",
       "           -1.4507e-01,  8.8743e-01],\n",
       "          [ 1.4145e+00,  5.8131e-01,  1.8325e+00,  ...,  1.2702e+00,\n",
       "            1.3220e+00, -1.0395e+00],\n",
       "          ...,\n",
       "          [-2.2786e+00, -1.2282e+00, -1.8462e+00,  ..., -1.8943e-01,\n",
       "           -1.6184e+00,  1.3940e+00],\n",
       "          [ 4.5204e-01,  1.3632e+00,  3.6513e-01,  ..., -5.1590e-01,\n",
       "           -5.2662e-01,  1.9107e-01],\n",
       "          [-5.8666e-02, -1.3744e+00,  1.9036e-01,  ..., -9.2207e-01,\n",
       "           -1.5555e+00,  1.3249e+00]],\n",
       "\n",
       "         [[ 1.2556e+00,  7.9786e-01,  5.5016e-02,  ..., -9.2669e-01,\n",
       "            1.7184e+00,  9.5488e-01],\n",
       "          [-2.8152e-01,  1.4642e+00, -9.3359e-01,  ..., -1.2772e-01,\n",
       "           -1.6461e-01,  1.1878e-01],\n",
       "          [-6.4176e-01, -1.9661e+00,  4.0120e-01,  ...,  1.2389e-01,\n",
       "           -7.7685e-01, -1.5504e+00],\n",
       "          ...,\n",
       "          [ 6.5877e-01,  4.9327e-01,  1.8125e-01,  ..., -3.9329e-01,\n",
       "            1.3964e+00, -1.2351e+00],\n",
       "          [ 1.9054e-01,  3.9811e-01, -1.8334e+00,  ..., -7.7263e-01,\n",
       "            6.8484e-02, -7.6812e-01],\n",
       "          [ 3.1801e-01, -8.5731e-01,  6.9359e-01,  ..., -1.3111e+00,\n",
       "            5.2107e-01,  1.0797e+00]],\n",
       "\n",
       "         [[ 2.1521e-01, -5.4677e-01, -1.8686e+00,  ...,  4.1756e-01,\n",
       "           -1.6248e-01,  1.8721e+00],\n",
       "          [-8.4487e-01,  4.0168e-01, -2.8288e-02,  ..., -3.8775e-01,\n",
       "            3.9039e-01,  5.7524e-02],\n",
       "          [-9.7176e-01, -2.1540e+00, -1.0912e+00,  ..., -1.2912e+00,\n",
       "            7.4053e-01, -2.6190e-01],\n",
       "          ...,\n",
       "          [ 1.0232e+00,  2.1944e+00, -2.0213e+00,  ..., -6.2265e-01,\n",
       "            1.3684e+00, -1.6665e+00],\n",
       "          [-1.1413e+00, -9.5457e-01, -9.8640e-01,  ..., -6.8841e-01,\n",
       "            3.1651e-01, -1.1231e+00],\n",
       "          [ 1.3413e+00,  2.5587e-01, -4.9744e-01,  ..., -8.1298e-01,\n",
       "            9.8327e-01,  5.5059e-01]],\n",
       "\n",
       "         [[-1.7612e+00,  6.8601e-01,  1.1325e+00,  ..., -6.1020e-01,\n",
       "            4.4669e-01,  1.1687e+00],\n",
       "          [ 1.5622e+00,  1.5696e+00,  6.6853e-02,  ...,  9.7605e-01,\n",
       "           -1.2845e+00, -4.8605e-02],\n",
       "          [-1.2995e+00,  1.0681e+00,  4.7171e-01,  ..., -3.5969e-01,\n",
       "           -5.8060e-01, -1.6108e+00],\n",
       "          ...,\n",
       "          [-2.9687e-01, -1.6861e-01, -4.9574e-01,  ...,  4.5381e-01,\n",
       "           -5.3059e-01,  4.6774e-01],\n",
       "          [ 1.6893e+00, -2.8024e-01,  1.6464e+00,  ..., -1.0064e+00,\n",
       "           -1.2466e-01,  4.0304e-01],\n",
       "          [-9.1874e-01,  1.5175e-01,  3.3582e-01,  ...,  2.1212e-01,\n",
       "            7.4561e-01,  9.9763e-02]],\n",
       "\n",
       "         [[ 1.1428e+00,  2.4481e-01,  1.3804e+00,  ...,  2.6198e+00,\n",
       "            2.1981e+00,  6.7048e-01],\n",
       "          [-1.5887e+00, -6.1243e-01, -1.1078e+00,  ...,  9.1009e-01,\n",
       "            7.9161e-01, -5.1472e-01],\n",
       "          [-2.5771e-01, -1.8497e+00, -1.2805e-01,  ..., -8.2927e-01,\n",
       "            1.8364e+00, -7.5075e-01],\n",
       "          ...,\n",
       "          [ 5.1890e-01,  8.5749e-02, -4.2485e-01,  ...,  3.5606e-01,\n",
       "           -1.3756e+00, -1.4942e+00],\n",
       "          [-7.6615e-01,  5.0298e-01,  4.6855e-01,  ...,  1.4592e-03,\n",
       "           -1.1322e+00,  3.6812e-01],\n",
       "          [-9.3985e-01,  1.3369e+00,  4.9279e-03,  ..., -6.4427e-01,\n",
       "            7.3341e-01,  7.2042e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.1806e-01,  2.5262e+00,  4.7682e-01,  ..., -4.3791e-01,\n",
       "           -7.4744e-01,  1.1319e+00],\n",
       "          [-6.3712e-01,  8.4059e-01, -1.0538e+00,  ...,  8.0237e-01,\n",
       "            3.7184e-01, -8.9068e-01],\n",
       "          [-9.3879e-01, -8.4423e-01, -1.2849e+00,  ..., -7.3409e-01,\n",
       "           -3.6443e-01, -4.2621e-01],\n",
       "          ...,\n",
       "          [ 2.8441e-01,  4.1023e-01,  1.5418e+00,  ...,  5.0633e-01,\n",
       "           -5.4832e-01, -2.2466e+00],\n",
       "          [ 2.9062e-01,  5.9306e-01,  2.2053e-01,  ..., -3.2235e-01,\n",
       "            9.4073e-02,  8.8476e-01],\n",
       "          [-5.6054e-01,  2.2985e-01,  1.7049e+00,  ...,  2.8225e-01,\n",
       "            1.8430e+00,  2.5475e+00]],\n",
       "\n",
       "         [[-9.5255e-01, -1.9978e-01, -1.1592e+00,  ...,  3.7460e-01,\n",
       "            2.3260e-01, -1.2844e+00],\n",
       "          [ 2.6990e-01,  3.9588e-01,  7.9751e-02,  ..., -5.5174e-01,\n",
       "            8.4524e-02, -4.0092e-01],\n",
       "          [ 1.6835e+00,  2.1987e-01, -2.8153e-01,  ..., -2.0496e+00,\n",
       "           -3.4213e-02, -3.7258e+00],\n",
       "          ...,\n",
       "          [-1.4715e-01,  1.4721e+00, -5.7484e-01,  ..., -7.2670e-01,\n",
       "            1.7893e+00, -5.7153e-01],\n",
       "          [-1.5189e-01,  1.3728e+00, -1.7243e+00,  ..., -4.1699e-01,\n",
       "            6.3727e-01, -5.5688e-01],\n",
       "          [-1.5735e-01, -3.0054e-01, -4.0860e-01,  ...,  2.2642e+00,\n",
       "           -2.0065e+00, -1.1552e-02]],\n",
       "\n",
       "         [[ 1.0884e+00, -8.4969e-01, -2.6916e+00,  ..., -1.1990e+00,\n",
       "           -3.9051e-01, -4.8396e-01],\n",
       "          [ 3.3438e-01,  4.1531e-01, -1.7877e-01,  ...,  4.9355e-01,\n",
       "           -1.3657e+00,  5.5757e-01],\n",
       "          [-5.2049e-01, -7.8627e-01,  4.1844e-02,  ..., -5.9082e-01,\n",
       "            1.6477e+00, -2.0156e-01],\n",
       "          ...,\n",
       "          [-2.1871e+00,  9.9703e-02,  6.0601e-03,  ..., -7.9997e-01,\n",
       "            5.6718e-01, -1.9574e+00],\n",
       "          [ 1.2154e+00,  3.6996e-01,  6.5481e-01,  ...,  6.1594e-01,\n",
       "            7.5283e-02,  2.4039e-01],\n",
       "          [-9.6073e-01,  5.1671e-02,  1.3397e+00,  ..., -7.9401e-01,\n",
       "           -9.4677e-01, -3.8210e-01]],\n",
       "\n",
       "         [[ 2.8074e-01, -1.5288e+00, -6.1086e-02,  ...,  1.3170e-01,\n",
       "           -4.4456e-01, -1.2674e+00],\n",
       "          [-5.8925e-01,  4.0013e-01, -1.4190e+00,  ..., -1.2089e+00,\n",
       "           -2.6104e-01,  7.2525e-01],\n",
       "          [-1.4879e-01,  8.1540e-01,  9.8198e-02,  ..., -8.1780e-01,\n",
       "           -8.5419e-01, -1.7015e+00],\n",
       "          ...,\n",
       "          [-1.7517e-01,  9.5898e-01, -1.4596e+00,  ...,  1.7837e-01,\n",
       "           -7.0678e-01, -1.2764e-01],\n",
       "          [-4.9826e-01, -3.5083e-01, -5.6679e-01,  ..., -1.9377e-01,\n",
       "           -3.9216e-01, -1.5873e+00],\n",
       "          [ 1.9279e-01, -4.5289e-01,  2.7174e+00,  ...,  1.2479e+00,\n",
       "           -8.8216e-01, -3.9500e-01]],\n",
       "\n",
       "         [[-1.5900e+00,  3.1728e-01, -6.1675e-01,  ...,  9.7799e-02,\n",
       "            1.5896e-01, -6.0488e-01],\n",
       "          [-1.2679e+00,  7.6571e-02,  5.2075e-01,  ...,  1.5235e+00,\n",
       "           -1.1964e+00, -2.5660e-01],\n",
       "          [ 9.0531e-02, -1.6759e-01, -6.5117e-01,  ...,  1.4153e+00,\n",
       "           -1.3319e+00,  1.1119e+00],\n",
       "          ...,\n",
       "          [-1.0750e+00, -1.6447e+00,  7.8727e-01,  ...,  2.6387e-01,\n",
       "            6.7586e-01, -2.2466e-01],\n",
       "          [-7.0834e-01,  4.8556e-01, -1.4636e-02,  ...,  1.1923e+00,\n",
       "           -7.5585e-01, -3.2510e+00],\n",
       "          [ 4.3289e-01,  6.1587e-01, -4.2493e-02,  ..., -2.6605e-01,\n",
       "            6.4412e-01,  2.4782e-01]]]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8504, -1.0663, -0.1785,  ..., -0.7551,  1.0224, -1.2777],\n",
       "         [ 0.7548,  0.0642, -0.3849,  ..., -0.6614, -0.1451,  0.8874],\n",
       "         [ 1.4145,  0.5813,  1.8325,  ...,  1.2702,  1.3220, -1.0395],\n",
       "         ...,\n",
       "         [-2.2786, -1.2282, -1.8462,  ..., -0.1894, -1.6184,  1.3940],\n",
       "         [ 0.4520,  1.3632,  0.3651,  ..., -0.5159, -0.5266,  0.1911],\n",
       "         [-0.0587, -1.3744,  0.1904,  ..., -0.9221, -1.5555,  1.3249]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1[:, 9, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hanshi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
