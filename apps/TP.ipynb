{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "import torch\n",
    "\n",
    "def distributed_init():\n",
    "\n",
    "    dist.init_process_group(backend=\"nccl\")\n",
    "    local_rank = dist.get_rank()\n",
    "    world_size = dist.get_world_size()\n",
    "    torch.cuda.set_device(local_rank)\n",
    "\n",
    "    return local_rank, world_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_free_port():\n",
    "    \"\"\" https://stackoverflow.com/questions/1365265/on-localhost-how-do-i-pick-a-free-port-number \"\"\"\n",
    "    import socket\n",
    "    from contextlib import closing\n",
    "\n",
    "    with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as s:\n",
    "        s.bind(('', 0))\n",
    "        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
    "        return str(s.getsockname()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = 2\n",
    "master_addr = '127.0.0.1'\n",
    "master_port = find_free_port()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'57727'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "rank = 0\n",
    "backend = 'nccl'\n",
    "\n",
    "print(f'setting up {rank=} {world_size=} {backend=}')\n",
    "\n",
    "# set up the master's ip address so this child process can coordinate\n",
    "os.environ['MASTER_ADDR'] = master_addr\n",
    "os.environ['MASTER_PORT'] = master_port\n",
    "print(f\"{master_addr=} {master_port=}\")\n",
    "\n",
    "# Initializes the default distributed process group, and this will also initialize the distributed package.\n",
    "dist.init_process_group(backend, rank=rank, world_size=world_size, timeout=timedelta(seconds=30), init_method=\"env://\")\n",
    "print(f\"{rank=} init complete\")\n",
    "dist.destroy_process_group()\n",
    "print(f\"{rank=} destroy complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=6,7 OMP_NUM_THREADS=48 torchrun --nproc_per_node=2 test/TP_baseline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 384 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 512 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 640 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 768 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 896 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 1024 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 1152 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 1280 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 1408 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 1536 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 1664 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 1792 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 1920 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 2048 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 2176 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 2304 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 2432 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 2560 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 2688 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 2816 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 2944 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 3072 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 3200 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 3328 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 3456 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 3584 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 3712 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 3840 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 3968 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 4096 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 4224 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 4352 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 4480 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 4608 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 4736 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 4864 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 4992 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 5120 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 5248 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 5376 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 5504 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 5632 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 5760 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 5888 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 6016 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 6144 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 6272 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 6400 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 6528 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 6656 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 6784 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 6912 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 7040 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 7168 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 7296 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 7424 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 7552 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 7680 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 7808 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 7936 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 8064 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 8192 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 8320 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 8448 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 8576 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 8704 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 8832 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 8960 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 9088 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 9216 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 9344 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 9472 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 9600 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 9728 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 9856 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 9984 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 10112 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 10240 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 10368 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 10496 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 10624 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 10752 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 10880 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 11008 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 11136 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 11264 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 11392 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 11520 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 11648 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 11776 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 11904 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 12032 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 12160 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 12288 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 12416 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 12544 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n",
      "CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill 122880 --budget 12672 --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 100):\n",
    "    print(f\"CUDA_VISIBLE_DEVICES=0 python test/e2e_ablation.py --prefill {122880} --budget {128*i} --chunk_size 8 --top_p 0.9 --temp 0.6 --gamma 6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"JackFram/llama-68m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a much a my some a'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([263, 1568,  263,  590,  777,  263])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,8,9 OMP_NUM_THREADS=48 torchrun --nproc_per_node=8 test/TP_baseline.py --prefill 128 --bsz 128 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,8,9 OMP_NUM_THREADS=48 torchrun --nproc_per_node=8 test/TP_baseline.py --prefill 128 --bsz 64 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,8,9 OMP_NUM_THREADS=48 torchrun --nproc_per_node=8 test/TP_baseline.py --prefill 128 --bsz 32 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,8,9 OMP_NUM_THREADS=48 torchrun --nproc_per_node=8 test/TP_baseline.py --prefill 128 --bsz 16 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,8,9 OMP_NUM_THREADS=48 torchrun --nproc_per_node=8 test/TP_baseline.py --prefill 128 --bsz 8 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,8,9 OMP_NUM_THREADS=48 torchrun --nproc_per_node=8 test/TP_baseline.py --prefill 128 --bsz 4 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,8,9 OMP_NUM_THREADS=48 torchrun --nproc_per_node=8 test/TP_baseline.py --prefill 128 --bsz 2 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,8,9 OMP_NUM_THREADS=48 torchrun --nproc_per_node=8 test/TP_baseline.py --prefill 128 --bsz 1 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1,2,3,4 OMP_NUM_THREADS=48 torchrun --nproc_per_node=4 test/TP_baseline.py --prefill 128 --bsz 128 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1,2,3,4 OMP_NUM_THREADS=48 torchrun --nproc_per_node=4 test/TP_baseline.py --prefill 128 --bsz 64 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1,2,3,4 OMP_NUM_THREADS=48 torchrun --nproc_per_node=4 test/TP_baseline.py --prefill 128 --bsz 32 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1,2,3,4 OMP_NUM_THREADS=48 torchrun --nproc_per_node=4 test/TP_baseline.py --prefill 128 --bsz 16 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1,2,3,4 OMP_NUM_THREADS=48 torchrun --nproc_per_node=4 test/TP_baseline.py --prefill 128 --bsz 8 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1,2,3,4 OMP_NUM_THREADS=48 torchrun --nproc_per_node=4 test/TP_baseline.py --prefill 128 --bsz 4 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1,2,3,4 OMP_NUM_THREADS=48 torchrun --nproc_per_node=4 test/TP_baseline.py --prefill 128 --bsz 2 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1,2,3,4 OMP_NUM_THREADS=48 torchrun --nproc_per_node=4 test/TP_baseline.py --prefill 128 --bsz 1 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1,2 OMP_NUM_THREADS=48 torchrun --nproc_per_node=2 test/TP_baseline.py --prefill 128 --bsz 128 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1,2 OMP_NUM_THREADS=48 torchrun --nproc_per_node=2 test/TP_baseline.py --prefill 128 --bsz 64 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1,2 OMP_NUM_THREADS=48 torchrun --nproc_per_node=2 test/TP_baseline.py --prefill 128 --bsz 32 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1,2 OMP_NUM_THREADS=48 torchrun --nproc_per_node=2 test/TP_baseline.py --prefill 128 --bsz 16 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1,2 OMP_NUM_THREADS=48 torchrun --nproc_per_node=2 test/TP_baseline.py --prefill 128 --bsz 8 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1,2 OMP_NUM_THREADS=48 torchrun --nproc_per_node=2 test/TP_baseline.py --prefill 128 --bsz 4 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1,2 OMP_NUM_THREADS=48 torchrun --nproc_per_node=2 test/TP_baseline.py --prefill 128 --bsz 2 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1,2 OMP_NUM_THREADS=48 torchrun --nproc_per_node=2 test/TP_baseline.py --prefill 128 --bsz 1 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1 OMP_NUM_THREADS=48 torchrun --nproc_per_node=1 test/TP_baseline.py --prefill 128 --bsz 128 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1 OMP_NUM_THREADS=48 torchrun --nproc_per_node=1 test/TP_baseline.py --prefill 128 --bsz 64 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1 OMP_NUM_THREADS=48 torchrun --nproc_per_node=1 test/TP_baseline.py --prefill 128 --bsz 32 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1 OMP_NUM_THREADS=48 torchrun --nproc_per_node=1 test/TP_baseline.py --prefill 128 --bsz 16 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1 OMP_NUM_THREADS=48 torchrun --nproc_per_node=1 test/TP_baseline.py --prefill 128 --bsz 8 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1 OMP_NUM_THREADS=48 torchrun --nproc_per_node=1 test/TP_baseline.py --prefill 128 --bsz 4 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1 OMP_NUM_THREADS=48 torchrun --nproc_per_node=1 test/TP_baseline.py --prefill 128 --bsz 2 --gen_len 32\n",
      "CUDA_VISIBLE_DEVICES=1 OMP_NUM_THREADS=48 torchrun --nproc_per_node=1 test/TP_baseline.py --prefill 128 --bsz 1 --gen_len 32\n"
     ]
    }
   ],
   "source": [
    "bsz_list = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "cuda_list = ['1', '1,2', '1,2,3,4', '1,2,3,4,5,6,8,9']\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=5,6 OMP_NUM_THREADS=48 torchrun --nproc_per_node=2 test/TP_baseline.py --prefill 128 --bsz 1 --gen_len 32\n",
    "\n",
    "for cuda in reversed(cuda_list):\n",
    "    for bsz in reversed(bsz_list):\n",
    "        print(f\"CUDA_VISIBLE_DEVICES={cuda} OMP_NUM_THREADS=48 torchrun --nproc_per_node={len(cuda)//2+1} test/TP_baseline.py --prefill 128 --bsz {bsz} --gen_len 32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
